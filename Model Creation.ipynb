{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from utils import *\n",
    "from text_preprocessing import *\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df shape:  (3000, 9)\n",
      "\n",
      "rows with null values:  Int64Index([1551, 1552], dtype='int64')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author.properties.friends</th>\n",
       "      <th>author.properties.status_count</th>\n",
       "      <th>author.properties.verified</th>\n",
       "      <th>content.body</th>\n",
       "      <th>location.country</th>\n",
       "      <th>location.latitude</th>\n",
       "      <th>location.longitude</th>\n",
       "      <th>properties.sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>|| TELL ME YOUR NAME! XD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>twitter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     author.properties.friends  author.properties.status_count  \\\n",
       "1552  || TELL ME YOUR NAME! XD                             NaN   \n",
       "\n",
       "     author.properties.verified content.body location.country  \\\n",
       "1552                    twitter          NaN              NaN   \n",
       "\n",
       "      location.latitude  location.longitude  properties.sentiment  \n",
       "1552                NaN                 NaN                   NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest_ = load_combined_df()\n",
    "\n",
    "\n",
    "print('\\nrows with null values: ',dftest_[dftest_.isnull().any(axis=1)].index)\n",
    "\n",
    "dftest_ = dftest_.drop(['properties.platform'],axis=1)\n",
    "\n",
    "dftest_[dftest_.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Projects\\bitbucket\\fancy-a-challenge-william\\utils.py:16: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  combined_df = pd.concat([csv_df,txt_df])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df shape:  (3000, 9)\n",
      "\n",
      "rows with null values:  Int64Index([1551, 1552], dtype='int64')\n",
      "rows that arent twitter:  2\n",
      "\n",
      "dropped one row, fixed other null by dropping platform col, as unneeded\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-fc927e5cd7d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcombined_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_combined_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Projects\\bitbucket\\fancy-a-challenge-william\\utils.py\u001b[0m in \u001b[0;36mpreprocess_values\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\ndropped one row, fixed other null by dropping platform col, as unneeded'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m#convert friends to numeric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "combined_df = preprocess_values(load_combined_df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: author.properties.verified\n"
     ]
    }
   ],
   "source": [
    "nlp_df = normalize(encode_labels(combined_df.drop(['location.country','location.latitude','location.longitude'],axis=1),['author.properties.verified']),['author.properties.friends','author.properties.status_count'])\n",
    "nlp_df['content.body'].head(1).values\n",
    "preprocess_text(nlp_df['content.body'].head(1).values[0])\n",
    "nlp_df['content.body'] = nlp_df['content.body'].apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wburke\\projects\\venv36\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5    @sarahann_jones @heatherpeace @seachell74 @HP_...\n",
       "5    All I want is for my @JeffreeStar order to arr...\n",
       "5         @ItsMqtt_ Try to get tickets @Jorduunn ^^ ðŸ˜ƒðŸ˜ƒ\n",
       "Name: content.body, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                cannot believe i am missing love island\n",
       "1      last tweet about future wedding if i actually ...\n",
       "2      how many times does he wonna say the phrase i ...\n",
       "3      even better if time travel were invented and i...\n",
       "4      greenalty shakeystephens my mum in mid ##s pus...\n",
       "5      sarahann jones heatherpeace seachell## hp comm...\n",
       "6      folk at level ## running around in reaper mari...\n",
       "7                     just want money so i can move away\n",
       "8      ray1moses cornerstone hq rice flour then does ...\n",
       "9                                                       \n",
       "10     club penguin blocked me for saying 'fucking' a...\n",
       "11     british museum pays tribute to zinedine zidane...\n",
       "12                               word httpstcogqytwlr1pj\n",
       "13     ellathomasxo should have accidentally on purpo...\n",
       "14     #### bst experimental forecast for the next ##...\n",
       "15                                 i should really sleep\n",
       "16            lit me and orange peels httpstcoblxtupghfn\n",
       "17                  my do my toes never stay in my heels\n",
       "18     skynews he really is a clown that is perhaps a...\n",
       "19     garyskiphills nope i take your point there i f...\n",
       "20               ooh i understand now httpstco8hcnvxvqp0\n",
       "21     alicestevo john eastman httpstco##vfdicttm htt...\n",
       "22                           flyy7f yer wee brer's in pk\n",
       "23     weather chart for past ## hours autotweet with...\n",
       "24     #### bst temperature ###c wind w 1 mph ave 7 m...\n",
       "25     barlow## just lay in my coffin for a few hours...\n",
       "26         just realised i have not eaten anything today\n",
       "27                               httpstcokgxnekggkk this\n",
       "28     mattyfairnie fave album not a bold shout tbf i...\n",
       "29                     manufacturinguk derby greendavidd\n",
       "                             ...                        \n",
       "970    good stuff anyone else entered pls##krace yet ...\n",
       "971                                  literally so fed up\n",
       "972    cityalan mohospark love it the past coming to ...\n",
       "973    soapstars2k yup if we learned anything from th...\n",
       "974                        jamesgent## ah finally a wank\n",
       "975                     ste collins not just me then lol\n",
       "976    what do you think of httpstcow1ymcdhxgm luha c...\n",
       "977                                    indiegates hahaha\n",
       "978    omarabushaib hey there was wondering if you wa...\n",
       "979    we all agree hitler should not have got to pow...\n",
       "980    what was worse alastair losing at home to anna...\n",
       "981    comedyrtgrp cheers for the rt comedyretweetgro...\n",
       "982    shinybluedress dorset eye katewritesstuff moor...\n",
       "983           season 4 of orphan black is amazing though\n",
       "984    mikkil shazza1uk staranderton suzanne evans ve...\n",
       "985                ordlnaryus sonuna kadar aziz yildirim\n",
       "986    always knew it was never going to happen mindg...\n",
       "987    booooooooooom sign of the kodiac wins for memb...\n",
       "988                                                     \n",
       "989                         truestory httpstcoturywhb2et\n",
       "990    stacemusic this is a bit more complicated than...\n",
       "991    #### bst temperature ###c wind sw 2 mph ave 9 ...\n",
       "992    equality fem redzos## it does not matter how t...\n",
       "993    ### days until the walking dead returns httpst...\n",
       "994    char lang move on na ako mag ayos na ako oy hi...\n",
       "995    er stationery weddinghour tinareading nawpuk s...\n",
       "996    what to do now just finished the final episode...\n",
       "997                          np shola ama loving my baby\n",
       "998    could not have had a worse couple days failed ...\n",
       "999    fhpreading hi guys we are from reading and wou...\n",
       "Name: content.body, Length: 2997, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_df['content.body'].apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
